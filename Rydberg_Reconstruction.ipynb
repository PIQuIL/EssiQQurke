{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qucumber.nn_states import PositiveWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.data as data\n",
    "import qucumber\n",
    "\n",
    "import torch\n",
    "\n",
    "# set random seed on cpu but not gpu, as gpu is not used\n",
    "qucumber.set_random_seed(1234, cpu=True, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 8])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we get the training data\n",
    "# Training data is given in the data/nY=8/ directory for each delta\n",
    "# in the '...samples.csv' files.\n",
    "# So the delta needs to be specified below\n",
    "\n",
    "#-------------------- Specify delta and nY ---------------------#\n",
    "delta = \"1.04\" \n",
    "nY = \"8\" # nY refers to the number of atoms in the array\n",
    "# For the nY = 8 system case:\n",
    "# delta is any of 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20\n",
    "# For nY > 8:\n",
    "# delta is any of 1.00, 1.04, 1.08, 1.12, 1.16, 1.20, 1.28\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "train_path = \"data/nY=\"+nY+\"/Î´=\"+delta+\"_samples.csv\"\n",
    "train_data = data.load_data(train_path)\n",
    "\n",
    "# The training data is stored in train_data[0]\n",
    "# and the dimension of the data is:\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we have the training data. Our goal is to train a\n",
    "# Restricted Boltzman Machine using this training data. We use\n",
    "# QuCumber to create an instance of an RBM. First we need to specify the \n",
    "# number of visible nodes (nv) and number of higgen nodes (nh). \n",
    "# As we have an array of 8 atoms, we have 6 inputs and so nv = 8\n",
    "nv = train_data[0].shape[-1]\n",
    "\n",
    "# Number of hidden nodes of an RBM is a hyperparameter which depends on the \n",
    "# data we are using and which can be varied to get optimal result. \n",
    "# For this problem, nh was varied from 4 to 8 and nh = 8 gave quite good results.\n",
    "# Hence, we set nh = 8.\n",
    "nh = 8\n",
    "\n",
    "# Finally we create an RBM with nv visible nodes and nh  hidden nodes.\n",
    "nn_state = PositiveWaveFunction(num_visible=nv, num_hidden=nh, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed during training: 113.514 s\n"
     ]
    }
   ],
   "source": [
    "# Below we have more hyperparameters of the RBM model. Like the number of \n",
    "# hidden nodes, the parameters below can be varied to get optimal results.\n",
    "# The following hyperparameters seemed to work quite well. Note that when\n",
    "# you have different data, then different values of the hyperparameter will give\n",
    "# better solutions. \n",
    "# Further description of the parameters (if you are curious) is in:\n",
    "# https://qucumber.readthedocs.io/en/stable/quantum_states.html?highlight=fit#qucumber.nn_states.PositiveWaveFunction.fit\n",
    "\n",
    "epochs = 500\n",
    "pbs = 100\n",
    "nbs = pbs\n",
    "lr = 0.0065 \n",
    "k = 10\n",
    "\n",
    "# Now we train our RBM using the above parameters. \n",
    "# Note that the training process will take 2 - 3 minutes\n",
    "\n",
    "nn_state.fit(\n",
    "    train_data[0],\n",
    "    epochs=epochs,\n",
    "    pos_batch_size=pbs,\n",
    "    neg_batch_size=nbs,\n",
    "    lr=lr,\n",
    "    k=k,\n",
    "    time=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbm_am': OrderedDict([('weights',\n",
       "               tensor([[ 1.3587, -2.1112,  1.6800, -0.8456, -0.1849,  0.3550, -0.4630, -0.4166],\n",
       "                       [ 0.1871,  0.3049, -1.0210,  1.0056, -0.7880, -0.0321,  0.4994, -0.7517],\n",
       "                       [ 0.0505,  0.6470, -0.6218, -0.8277,  2.0811, -2.8360,  2.3953, -1.5319],\n",
       "                       [-1.4465,  0.6002, -0.4012,  0.0931, -0.6093,  0.8346, -1.6377,  1.6565],\n",
       "                       [-2.6099,  1.3747, -0.1745, -0.6722,  0.5136,  0.1548, -1.5352,  2.4759],\n",
       "                       [-0.7299,  1.3422, -2.6069,  2.3921, -1.8428,  0.4468, -0.0578, -0.3527],\n",
       "                       [ 1.0107, -0.8985, -0.0631,  1.0665, -1.7709,  1.4350, -0.5167, -0.5538],\n",
       "                       [ 1.0418, -1.6064,  1.4373, -1.6820,  1.1698, -1.2634,  0.6325, -1.1206]],\n",
       "                      dtype=torch.float64)),\n",
       "              ('visible_bias',\n",
       "               tensor([-0.8279, -1.0203, -0.4945, -1.4392, -0.5224, -0.7718, -0.9102, -0.9203],\n",
       "                      dtype=torch.float64)),\n",
       "              ('hidden_bias',\n",
       "               tensor([ 0.2612,  0.1040,  0.3748, -0.0354,  0.2417, -0.1466,  0.2230,  0.0754],\n",
       "                      dtype=torch.float64))])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training is complete, we save the parameters of the trained RBM below\n",
    "# as rydberg_data.pt in the output directory.\n",
    "nn_state.save(\"output/rydberg_data.pt\")\n",
    "torch.load(\"output/rydberg_data.pt\")\n",
    "# Below we have the parameters  (weights and biases) of the trained RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have our trained RBM. Here we reconstruct the wavefunction by sampling from the RBM. \n",
    "# Let us see step by step how it works -\n",
    "\n",
    "# The first step is to sample from our trained RBM using QuCumber.\n",
    "# We then get num_samples samples which is stored in the variable 'samples'\n",
    "num_samples = 5000\n",
    "samples = nn_state.sample(num_samples = num_samples , k = 10)\n",
    "\n",
    "# Now we print out the samples in 'output/reconstructedSample.txt'\n",
    "sampleList = samples.tolist() # convert to list for convenience\n",
    "sampleList\n",
    "with open('output/reconstructedSample.txt', 'w') as fp:\n",
    "    for item in sampleList:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the samples we obtain the amplitudes of each of the basis states.\n",
    "# Note that here we have an 8 atom array. Hencem there are 2^8 basis states\n",
    "# which are: |00000000>, |00000001>, ..., |11111111>\n",
    "\n",
    "# Now say X is any of the states from {|00000000>, |00000001>, ..., |11111111>}\n",
    "# Now, the amplitude of a state X is computed by taking the\n",
    "# square root of the number of states X present in \n",
    "# our produced sample in in 'output/reconstructedSample.txt'.\n",
    "\n",
    "# Therefore the reconstructed sample is like: \n",
    "#    |psi> = amplitudeList[0] |00000000> + amplitudeList[1] |00000001> + ... + amplitudeList[255] |11111111>  \n",
    "# where amplitudeList is defined below.\n",
    "\n",
    "# The following functions below finds the amplitudes in the way described above, stores the \n",
    "# amplitudes in amplitudeList and then also \n",
    "# prints out the amplitudes in 'output/reconstructedSample.txt'\n",
    "\n",
    "def amplitude(sample):\n",
    "    return np.sqrt(sampleList.count(sample)/num_samples)\n",
    "\n",
    "def getBinaryString(i):\n",
    "    sites = nv # nv = 8\n",
    "    getbinary = lambda x, n: format(x, 'b').zfill(n)\n",
    "    tempStr = getbinary(i, sites)\n",
    "    return tempStr\n",
    "\n",
    "# Python code to convert string to list character-wise\n",
    "def ConvertToList(string):\n",
    "    list1=[]\n",
    "    list1[:0]=string\n",
    "    return list1\n",
    "\n",
    "amplitudeList = []\n",
    "def getAmplitude(sample):\n",
    "    for i in range (2**nv):\n",
    "        binaryString = getBinaryString(i)\n",
    "        strList = ConvertToList(binaryString)\n",
    "        tempStr = str(amplitude(list(map(int, strList))))\n",
    "        amplitudeList.append(tempStr)\n",
    "    return 0\n",
    "\n",
    "getAmplitude(sampleList)\n",
    "with open('output/reconstructedStateAmplitudes.txt', 'w') as fp:\n",
    "    for item in amplitudeList:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3956, 0.3444, 0.4142, 0.3424, 0.4216, 0.3534, 0.4012, 0.369]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we have obtained the reconstructed wavefunction.\n",
    "# Now in the 'data' directory for each delta we have 1_pt_fun and 2_pt_fn\n",
    "# 1_pt_fn is the one point function and \n",
    "# 2_pt_fn is the 2 point function.\n",
    "\n",
    "# 1_pt_fn is the average occupation of each site. Note that\n",
    "# there are 8 sites as there are 8 atoms. Occupation of each site\n",
    "# refers to the proportion of atoms in the up state (state 1) \n",
    "# in each state.\n",
    "\n",
    "# Now we get average occupation of each site by finding the \n",
    "# number of atoms in the up state in each site and then\n",
    "# by dividing by the number of the produced samples \n",
    "occupation = [0]*nv\n",
    "for i in range(len(sampleList)):\n",
    "    j = 0\n",
    "    for j in range(nv):\n",
    "        occupation[j] = sampleList[i][j] + occupation[j]\n",
    "for i in range(nv):\n",
    "    occupation[i] = occupation[i]/len(sampleList)\n",
    "\n",
    "# Thus the average occupation per site of each site for the reconstructed state is given below\n",
    "# This data can be compared to data/nY=8/Î´=delta_1_pt_fn.csv for the relevant delta\n",
    "\n",
    "# (Note: The list in data/nY=8/Î´=delta_1_pt_fn.csv was obtained from \n",
    "# the sample in data/nY=8/Î´=delta_samples.csv)\n",
    "\n",
    "# Thus the data in 'occupation' and 'data/nY=8/Î´=delta_1_pt_fn.csv' are expected to be close (which they are)\n",
    "occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23910064, -0.11004464,  0.10274248, -0.08445344,  0.07501504,\n",
       "        -0.08340504,  0.10528528, -0.1239764 ],\n",
       "       [-0.11004464,  0.22578864, -0.11465048,  0.10287744, -0.08159904,\n",
       "         0.07268904, -0.08197328,  0.1045164 ],\n",
       "       [ 0.10274248, -0.11465048,  0.24263836, -0.11622208,  0.09817328,\n",
       "        -0.08257828,  0.07862296, -0.0876398 ],\n",
       "       [-0.08445344,  0.10287744, -0.11622208,  0.22516224, -0.11535584,\n",
       "         0.10679584, -0.08457088,  0.0808544 ],\n",
       "       [ 0.07501504, -0.08159904,  0.09817328, -0.11535584,  0.24385344,\n",
       "        -0.11979344,  0.10705408, -0.0881704 ],\n",
       "       [-0.08340504,  0.07268904, -0.08257828,  0.10679584, -0.11979344,\n",
       "         0.22850844, -0.11418408,  0.1055954 ],\n",
       "       [ 0.10528528, -0.08197328,  0.07862296, -0.08457088,  0.10705408,\n",
       "        -0.11418408,  0.24023856, -0.1162428 ],\n",
       "       [-0.1239764 ,  0.1045164 , -0.0876398 ,  0.0808544 , -0.0881704 ,\n",
       "         0.1055954 , -0.1162428 ,  0.232839  ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we look at the 2 point function\n",
    "# 2 point function is the covariance matrix for occupations.\n",
    "# It is found by 2_pt_fn = outerProdT1 - OuterProdT2\n",
    "\n",
    "# outerProdT1 is the average of the outer product of the spin vectors with themselves\n",
    "# So we first find the sum of the outerproducts of the spin vectors with themselves.\n",
    "# Then we take the average\n",
    "outerProdT1 = np.zeros((nv,nv))\n",
    "for i in range(len(sampleList)):\n",
    "    outerProdT1 = outerProdT1 + np.outer(sampleList[i], sampleList[i])\n",
    "outerProdT1 = outerProdT1/len(sampleList)\n",
    "\n",
    "# outerProd2 is simply the outer product of the occupation vector\n",
    "# with itself. Note that we already found the occupation vector for the \n",
    "# one point function\n",
    "\n",
    "outerProdT2 = np.outer(occupation,occupation)\n",
    "outerProdT2\n",
    "\n",
    "#Hence we have:\n",
    "TwoPointFunc = outerProdT1 - outerProdT2\n",
    "\n",
    "# The TwoPointFunction data for the reconstructed state is given below.\n",
    "# This matrix can be compared to data/nY=8/Î´=delta_2_pt_fn.csv for the relevant delta\n",
    "\n",
    "# (Note: The matrix in data/nY=8/Î´=delta_2_pt_fn.csv was obtained from \n",
    "# the sample in data/nY=8/Î´=delta_samples.csv)\n",
    "\n",
    "# Thus the matrix in 'TwoFuncPoint' and 'data/nY=8/Î´=delta_2_pt_fn.csv' are expected \n",
    "# to be nearly equal (which they are)\n",
    "\n",
    "# Note that the matrix in data/nY=8/Î´=delta_2_pt_fn.csv may be a bit misleading. \n",
    "# The matrix generated there is symmetric and this is why the values \n",
    "# below the diagonal were not computed. However the actual matrix is symmetric\n",
    "TwoPointFunc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
