{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we import the libraries\n",
    "import numpy as np\n",
    "\n",
    "from qucumber.nn_states import PositiveWaveFunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.data as data\n",
    "import qucumber\n",
    "\n",
    "import torch\n",
    "\n",
    "# set random seed on cpu but not gpu, as gpu is not used\n",
    "qucumber.set_random_seed(1234, cpu=True, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 8])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we get the training data\n",
    "# Training data is given in the data/nY=8/ directory for each delta\n",
    "# in the '...samples.csv' files.\n",
    "# So the delta needs to be specified below\n",
    "\n",
    "#-------------------- Specify delta and nY ---------------------#\n",
    "delta = \"1.00\" \n",
    "nY = \"8\" # nY refers to the number of atoms in the array\n",
    "# For the nY = 8 system case:\n",
    "# delta is any of 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20\n",
    "# For nY > 8:\n",
    "# delta is any of 1.00, 1.04, 1.08, 1.12, 1.16, 1.20, 1.28\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "train_path = \"data/nY=\"+nY+\"/δ=\"+delta+\"_samples.csv\"\n",
    "train_data = data.load_data(train_path)\n",
    "\n",
    "# The training data is stored in train_data[0]\n",
    "# and the dimension of the data is:\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we have the training data. Our goal is to train a\n",
    "# Restricted Boltzman Machine using this training data. We use\n",
    "# QuCumber to create an instance of an RBM. First we need to specify the \n",
    "# number of visible nodes (nv) and number of higgen nodes (nh). \n",
    "# As we have an array of 8 atoms, we have 6 inputs and so nv = 8\n",
    "nv = train_data[0].shape[-1]\n",
    "\n",
    "# Number of hidden nodes of an RBM is a hyperparameter which depends on the \n",
    "# data we are using and which can be varied to get optimal result. \n",
    "# For this problem, nh was varied from 4 to 8 and nh = 8 gave quite good results.\n",
    "# Hence, we set nh = 8.\n",
    "nh = 8\n",
    "\n",
    "# Finally we create an RBM with nv visible nodes and nh  hidden nodes.\n",
    "nn_state = PositiveWaveFunction(num_visible=nv, num_hidden=nh, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed during training: 97.395 s\n"
     ]
    }
   ],
   "source": [
    "# Below we have more hyperparameters of the RBM model. Like the number of \n",
    "# hidden nodes, the parameters below can be varied to get optimal results.\n",
    "# The following hyperparameters seemed to work quite well. Note that when\n",
    "# you have different data, then different values of the hyperparameter will give\n",
    "# better solutions. \n",
    "# Further description of the parameters (if you are curious) is in:\n",
    "# https://qucumber.readthedocs.io/en/stable/quantum_states.html?highlight=fit#qucumber.nn_states.PositiveWaveFunction.fit\n",
    "\n",
    "epochs = 500\n",
    "pbs = 100\n",
    "nbs = pbs\n",
    "lr = 0.001 \n",
    "k = 10\n",
    "\n",
    "# Now we train our RBM using the above parameters. \n",
    "# Note that the training process will take 2 - 3 minutes\n",
    "\n",
    "nn_state.fit(\n",
    "    train_data[0],\n",
    "    epochs=epochs,\n",
    "    pos_batch_size=pbs,\n",
    "    neg_batch_size=nbs,\n",
    "    lr=lr,\n",
    "    k=k,\n",
    "    time=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbm_am': OrderedDict([('weights',\n",
       "               tensor([[ 0.1520, -0.3587,  0.3225, -0.2330,  0.1379, -0.4873,  0.1531, -0.4687],\n",
       "                       [-0.1418,  0.0648, -0.4758,  0.1188, -0.4656, -0.0573, -0.0941,  0.1042],\n",
       "                       [ 0.8981, -0.8709,  0.5448, -1.0082,  0.8964, -1.1952,  0.9400, -1.1395],\n",
       "                       [-0.8938,  0.6814, -0.8762,  0.6327, -0.9269,  0.6350, -0.9376,  0.8760],\n",
       "                       [-1.2022,  0.4189, -0.5567,  0.5442, -0.6010,  0.4949, -0.7948,  0.7584],\n",
       "                       [-1.1071,  1.0802, -1.3340,  1.1901, -1.1784,  0.8716, -1.2130,  0.6818],\n",
       "                       [-0.2204,  0.1032, -0.4457,  0.2519, -0.3864,  0.2571, -0.1752,  0.0066],\n",
       "                       [ 0.9983, -1.4100,  1.1381, -1.2083,  1.0330, -1.5288,  1.1081, -1.3366]],\n",
       "                      dtype=torch.float64)),\n",
       "              ('visible_bias',\n",
       "               tensor([-0.3916, -0.5867, -0.1289, -0.8753, -0.2579, -0.4898, -0.4194, -0.5288],\n",
       "                      dtype=torch.float64)),\n",
       "              ('hidden_bias',\n",
       "               tensor([ 0.0759,  0.0316,  0.1680, -0.0311,  0.0507, -0.0080, -0.0438,  0.2219],\n",
       "                      dtype=torch.float64))])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training is complete, we save the parameters of the trained RBM below\n",
    "# as rydberg_data.pt in the output directory.\n",
    "nn_state.save(\"output/rydberg_data.pt\")\n",
    "torch.load(\"output/rydberg_data.pt\")\n",
    "# Below we have the parameters  (weights and biases) of the trained RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have our trained RBM. Here we reconstruct the wavefunction by sampling from the RBM. \n",
    "# Let us see step by step how it works -\n",
    "\n",
    "# The first step is to sample from our trained RBM using QuCumber.\n",
    "# We then get num_samples samples which is stored in the variable 'samples'\n",
    "num_samples = 10000\n",
    "samples = nn_state.sample(num_samples = num_samples , k = 10)\n",
    "\n",
    "# Now we print out the samples in 'output/reconstructedSample.txt'\n",
    "sampleList = samples.tolist() # convert to list for convenience\n",
    "sampleList\n",
    "with open('output/reconstructedSample.txt', 'w') as fp:\n",
    "    for item in sampleList:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------------- ##\n",
    "## This block of code computes amplitudes. For nY > 8, it is not necessary\n",
    "## to run this block as computation takes a lot of time.\n",
    "## -------------------------------------------------------------------- ##\n",
    "# From the samples we obtain the amplitudes of each of the basis states.\n",
    "# Note that here we have an 8 atom array. Hencem there are 2^8 basis states\n",
    "# which are: |00000000>, |00000001>, ..., |11111111>\n",
    "\n",
    "# Now say X is any of the states from {|00000000>, |00000001>, ..., |11111111>}\n",
    "# Now, the amplitude of a state X is computed by taking the\n",
    "# square root of the number of states X present in \n",
    "# our produced sample in in 'output/reconstructedSample.txt'.\n",
    "\n",
    "# Therefore the reconstructed sample is like: \n",
    "#    |psi> = amplitudeList[0] |00000000> + amplitudeList[1] |00000001> + ... + amplitudeList[255] |11111111>  \n",
    "# where amplitudeList is defined below.\n",
    "\n",
    "# The following functions below finds the amplitudes in the way described above, stores the \n",
    "# amplitudes in amplitudeList and then also \n",
    "# prints out the amplitudes in 'output/reconstructedSample.txt'\n",
    "\n",
    "def amplitude(sample):\n",
    "    return np.sqrt(sampleList.count(sample)/num_samples)\n",
    "\n",
    "def getBinaryString(i):\n",
    "    sites = nv # nv = 8\n",
    "    getbinary = lambda x, n: format(x, 'b').zfill(n)\n",
    "    tempStr = getbinary(i, sites)\n",
    "    return tempStr\n",
    "\n",
    "# Python code to convert string to list character-wise\n",
    "def ConvertToList(string):\n",
    "    list1=[]\n",
    "    list1[:0]=string\n",
    "    return list1\n",
    "\n",
    "amplitudeList = []\n",
    "def getAmplitude(sample):\n",
    "    for i in range (2**nv):\n",
    "        binaryString = getBinaryString(i)\n",
    "        strList = ConvertToList(binaryString)\n",
    "        tempStr = str(amplitude(list(map(int, strList))))\n",
    "        amplitudeList.append(tempStr)\n",
    "    return 0\n",
    "\n",
    "getAmplitude(sampleList)\n",
    "with open('output/reconstructedStateAmplitudes.txt', 'w') as fp:\n",
    "    for item in amplitudeList:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3832, 0.4181, 0.4046, 0.4084, 0.3992, 0.388, 0.4141, 0.4182]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we have obtained the reconstructed wavefunction.\n",
    "# Now in the 'data' directory for each delta we have 1_pt_fun and 2_pt_fn\n",
    "# 1_pt_fn is the one point function and \n",
    "# 2_pt_fn is the 2 point function.\n",
    "\n",
    "# 1_pt_fn is the average occupation of each site. Note that\n",
    "# there are 8 sites as there are 8 atoms. Occupation of each site\n",
    "# refers to the proportion of atoms in the up state (state 1) \n",
    "# in each state.\n",
    "\n",
    "# Now we get average occupation of each site by finding the \n",
    "# number of atoms in the up state in each site and then\n",
    "# by dividing by the number of the produced samples \n",
    "occupation = [0]*nv\n",
    "for i in range(len(sampleList)):\n",
    "    j = 0\n",
    "    for j in range(nv):\n",
    "        occupation[j] = sampleList[i][j] + occupation[j]\n",
    "for i in range(nv):\n",
    "    occupation[i] = occupation[i]/len(sampleList)\n",
    "\n",
    "# Thus the average occupation per site of each site for the reconstructed state is given below\n",
    "# This data can be compared to data/nY=8/δ=delta_1_pt_fn.csv for the relevant delta\n",
    "\n",
    "# (Note: The list in data/nY=8/δ=delta_1_pt_fn.csv was obtained from \n",
    "# the sample in data/nY=8/δ=delta_samples.csv)\n",
    "\n",
    "# Thus the data in 'occupation' and 'data/nY=8/δ=delta_1_pt_fn.csv' are expected to be close (which they are)\n",
    "occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24215004, -0.11189594,  0.11193926, -0.10494712,  0.110926  ,\n",
       "        -0.1104605 ,  0.11652092, -0.11033324],\n",
       "       [-0.11189594,  0.23609959, -0.11032761,  0.11131732, -0.111361  ,\n",
       "         0.11834675, -0.11260162,  0.11370114],\n",
       "       [ 0.11193926, -0.11032761,  0.24262119, -0.10594828,  0.113419  ,\n",
       "        -0.11139325,  0.11430798, -0.10515006],\n",
       "       [-0.10494712,  0.11131732, -0.10594828,  0.23330736, -0.106128  ,\n",
       "         0.112169  , -0.10734376,  0.10825672],\n",
       "       [ 0.110926  , -0.111361  ,  0.113419  , -0.106128  ,  0.2419    ,\n",
       "        -0.110725  ,  0.115998  , -0.106106  ],\n",
       "       [-0.1104605 ,  0.11834675, -0.11139325,  0.112169  , -0.110725  ,\n",
       "         0.23619375, -0.1165665 ,  0.1159505 ],\n",
       "       [ 0.11652092, -0.11260162,  0.11430798, -0.10734376,  0.115998  ,\n",
       "        -0.1165665 ,  0.24229116, -0.11393452],\n",
       "       [-0.11033324,  0.11370114, -0.10515006,  0.10825672, -0.106106  ,\n",
       "         0.1159505 , -0.11393452,  0.23477244]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we look at the 2 point function\n",
    "# 2 point function is the covariance matrix for occupations.\n",
    "# It is found by 2_pt_fn = outerProdT1 - OuterProdT2\n",
    "\n",
    "# outerProdT1 is the average of the outer product of the spin vectors with themselves\n",
    "# So we first find the sum of the outerproducts of the spin vectors with themselves.\n",
    "# Then we take the average\n",
    "outerProdT1 = np.zeros((nv,nv))\n",
    "for i in range(len(sampleList)):\n",
    "    outerProdT1 = outerProdT1 + np.outer(sampleList[i], sampleList[i])\n",
    "outerProdT1 = outerProdT1/len(sampleList)\n",
    "\n",
    "# outerProd2 is simply the outer product of the occupation vector\n",
    "# with itself. Note that we already found the occupation vector for the \n",
    "# one point function\n",
    "\n",
    "outerProdT2 = np.outer(occupation,occupation)\n",
    "outerProdT2\n",
    "\n",
    "#Hence we have:\n",
    "TwoPointFunc = outerProdT1 - outerProdT2\n",
    "\n",
    "# The TwoPointFunction data for the reconstructed state is given below.\n",
    "# This matrix can be compared to data/nY=8/δ=delta_2_pt_fn.csv for the relevant delta\n",
    "\n",
    "# (Note: The matrix in data/nY=8/δ=delta_2_pt_fn.csv was obtained from \n",
    "# the sample in data/nY=8/δ=delta_samples.csv)\n",
    "\n",
    "# Thus the matrix in 'TwoFuncPoint' and 'data/nY=8/δ=delta_2_pt_fn.csv' are expected \n",
    "# to be nearly equal (which they are)\n",
    "\n",
    "# Note that the matrix in data/nY=8/δ=delta_2_pt_fn.csv may be a bit misleading. \n",
    "# The matrix generated there is symmetric and this is why the values \n",
    "# below the diagonal were not computed. However the actual matrix is symmetric\n",
    "TwoPointFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
